{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pp\n",
    "URL = 'https://books.toscrape.com/'\n",
    "def explora_categoria(url):\n",
    "    \"\"\" A partir de la URL de la página principal de una categoría, devuelve el nombre\n",
    "        de la categoría y el número de libros \"\"\"\n",
    "    category_request=requests.get(url)\n",
    "    category_request.encoding = category_request.apparent_encoding  # Corregimos el encoding\n",
    "    html = category_request.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    etiquets=soup.find_all(\"strong\")\n",
    "    return (etiquets[0].text,int(etiquets[1].text))\n",
    "\n",
    "def categorias():\n",
    "    \"\"\" Devuelve un conjunto de parejas (nombre, número libros) de todas las categorías \"\"\"\n",
    "    r = requests.get(URL)\n",
    "    r.encoding = r.apparent_encoding  # Corregimos el encoding\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #https://www.crummy.com/software/BeautifulSoup/bs4/doc/#the-string-argument:~:text=soup.find_all(%22a%22%2C%20attrs%3D%7B%22class%22%3A%20%22sister%22%7D)\n",
    "    etiquetas = soup.find_all(\"div\",{'class':\"side_categories\"})\n",
    "    enlaces=etiquetas[0].find_all(\"a\")\n",
    "    return {explora_categoria(URL+enlace.attrs[\"href\"])for enlace in enlaces[1:]}\n",
    "    \n",
    "\n",
    "\n",
    "con=categorias()\n",
    "for c in con:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html\n",
      "('Voyager (Outlander #3)', 21.07, 5)\n",
      "('Girl in the Blue Coat', 46.83, 2)\n",
      "('The Red Tent', 35.66, 5)\n",
      "('The Marriage of Opposites', 28.08, 4)\n",
      "('The Guernsey Literary and Potato Peel Pie Society', 49.53, 1)\n",
      "('The House by the Lake', 36.95, 1)\n",
      "('Girl With a Pearl Earring', 26.77, 1)\n",
      "('Glory over Everything: Beyond The Kitchen House', 45.84, 3)\n",
      "('Forever and Forever: The Courtship of Henry Longfellow and Fanny Appleton', 29.69, 3)\n",
      "('A Flight of Arrows (The Pathfinders #2)', 55.53, 5)\n",
      "('Lilac Girls', 17.28, 2)\n",
      "('Love, Lies and Spies', 20.55, 2)\n",
      "('The Constant Princess (The Tudor Court #1)', 16.62, 3)\n",
      "('The Last Painting of Sara de Vos', 55.55, 2)\n",
      "('World Without End (The Pillars of the Earth #2)', 32.97, 4)\n",
      "('Tipping the Velvet', 53.74, 1)\n",
      "('A Paris Apartment', 39.01, 4)\n",
      "('The Invention of Wings', 37.34, 1)\n",
      "('Mrs. Houdini', 30.25, 5)\n",
      "('The Passion of Dolssa', 28.32, 5)\n"
     ]
    }
   ],
   "source": [
    "# APARTADO 2 #\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "URL = 'https://books.toscrape.com/'\n",
    "def url_categoria(nombre):\n",
    "    \"\"\" Devuelve la URL de la página principal de una categoría a partir de su nombre (ignorar\n",
    "        espacios al principio y final y también diferencias en mayúsculas/minúsculas) \"\"\"\n",
    "    r = requests.get(URL)\n",
    "    r.encoding = r.apparent_encoding  # Corregimos el encoding\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #https://www.geeksforgeeks.org/beautifulsoup-search-by-text-inside-a-tag/\n",
    "    etiquetas = soup.find_all(lambda tag: tag.name==\"a\" and tag.text.strip().lower()==nombre.strip().lower())\n",
    "    \n",
    "    if(len(etiquetas)==0):\n",
    "        return None\n",
    "    else:\n",
    "        return URL+etiquetas[0].attrs[\"href\"]\n",
    "\n",
    "print(url_categoria('Historical fiction'))\n",
    "\n",
    "#https://ellibrodepython.com/switch-python hemos visto que esto es mas eficiente que if else    \n",
    "def number(texto):\n",
    "    numeros={\n",
    "        'one':1,\n",
    "        'two':2,\n",
    "        'three':3,\n",
    "        'four':4,\n",
    "        'five':5\n",
    "    }\n",
    "    return numeros.get(texto.lower(),None)\n",
    "def libros_de_la_pagina(url):\n",
    "    \"\"\"\n",
    "    Devuelve un conjunto con todos los libros que se ven \n",
    "    \"\"\"\n",
    "    if url is None:\n",
    "        return None\n",
    "    r = requests.get(url)\n",
    "    r.encoding = r.apparent_encoding  # Corregimos el encoding\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    etiquetas=soup.find_all(\"article\",{'class':\"product_pod\"})\n",
    "    conjunto=set()\n",
    "    for etiqueta in etiquetas:\n",
    "        p=etiqueta.find(\"p\")\n",
    "        precio=etiqueta.find(\"p\",{'class':\"price_color\"}).text[1:]\n",
    "        titulo=etiqueta.find(\"h3\").find(\"a\").attrs[\"title\"]\n",
    "        c=(titulo,float(precio),number(p.attrs[\"class\"][1]))\n",
    "        conjunto.add(c)\n",
    "    for c in conjunto:\n",
    "        print(c)\n",
    "    return conjunto\n",
    "libros_de_la_pagina(url_categoria('Historical fiction'))\n",
    "\n",
    "\n",
    "def todas_las_paginas(url):\n",
    "    \"\"\" Sigue la paginación recopilando todas las URL *absolutas* atravesadas \"\"\"\n",
    "    \n",
    "\n",
    "def libros_categoria(nombre):\n",
    "    \"\"\" Dado el nombre de una categoría, devuelve un conjunto de tuplas \n",
    "        (titulo, precio, valoracion), donde el precio será un número real y la \n",
    "        valoración un número natural \"\"\"\n",
    "    ...\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
