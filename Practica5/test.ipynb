{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pp\n",
    "URL = 'https://books.toscrape.com/'\n",
    "def explora_categoria(url):\n",
    "    \"\"\" A partir de la URL de la página principal de una categoría, devuelve el nombre\n",
    "        de la categoría y el número de libros \"\"\"\n",
    "    category_request=requests.get(url)\n",
    "    # Corregimos el encoding\n",
    "    category_request.encoding = category_request.apparent_encoding\n",
    "    html = category_request.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #Se ha visto el patron de que siempre\n",
    "    #siempre el 1º strong es el nombre\n",
    "    #y el segundo cuantos libros hay en total\n",
    "    etiquetas=soup.find_all(\"strong\")\n",
    "    return (etiquetas[0].text,int(etiquetas[1].text))\n",
    "\n",
    "def categorias():\n",
    "    \"\"\" Devuelve un conjunto de parejas (nombre, número libros) de todas las categorías \"\"\"\n",
    "    r = requests.get(URL)\n",
    "    # Corregimos el encoding\n",
    "    r.encoding = r.apparent_encoding\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    etiquetas = soup.find_all(\"div\",{'class':\"side_categories\"})\n",
    "    enlaces=etiquetas[0].find_all(\"a\")\n",
    "    #Descartamos la primera porque siempre es books\n",
    "    return {explora_categoria(URL+enlace.attrs[\"href\"])for enlace in enlaces[1:]}\n",
    "    \n",
    "\n",
    "\n",
    "con=categorias()\n",
    "for libro_actual in con:\n",
    "    print(libro_actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Testament of Mary', 52.67, 4)\n",
      "('The Vacationers', 42.15, 4)\n",
      "('Dear Mr. Knightley', 11.21, 5)\n",
      "('Digital Fortress', 58.0, 5)\n",
      "('The Dinner Party', 56.54, 2)\n",
      "('My Name Is Lucy Barton', 41.56, 1)\n",
      "('The Firm', 45.56, 3)\n",
      "('Thirst', 17.27, 5)\n",
      "('The Silent Sister (Riley MacPherson #1)', 46.29, 5)\n",
      "('A Man Called Ove', 39.72, 1)\n",
      "('Eligible (The Austen Project #4)', 27.09, 3)\n",
      "('Three-Martini Lunch', 23.21, 3)\n",
      "('Last One Home (New Beginnings #1)', 59.98, 3)\n",
      "('The Course of Love', 16.78, 3)\n",
      "('Take Me with You', 45.21, 3)\n",
      "('Lila (Gilead #3)', 12.47, 3)\n",
      "('I Am Pilgrim (Pilgrim #1)', 10.6, 4)\n",
      "('Lies and Other Acts of Love', 45.14, 1)\n",
      "('Mothering Sunday', 13.34, 2)\n",
      "('Hystopia: A Novel', 21.96, 4)\n",
      "('The Da Vinci Code (Robert Langdon #2)', 22.96, 2)\n",
      "('The Art of Fielding', 22.1, 1)\n",
      "('Deception Point', 40.32, 4)\n",
      "('The High Mountains of Portugal', 51.15, 1)\n",
      "('The First Hostage (J.B. Collins #2)', 25.85, 3)\n",
      "('Mr. Mercedes (Bill Hodges Trilogy #1)', 28.9, 1)\n",
      "(\"The Husband's Secret\", 52.51, 5)\n",
      "('Siddhartha', 34.22, 5)\n",
      "(\"When I'm Gone\", 51.96, 3)\n",
      "('The Improbability of Love', 59.45, 1)\n",
      "('11/22/63', 48.48, 3)\n",
      "('Balloon Animals', 17.03, 3)\n",
      "('The Nightingale', 26.26, 4)\n",
      "('The Time Keeper', 27.88, 5)\n",
      "('Shtum', 55.84, 4)\n",
      "('We Love You, Charlie Freeman', 50.27, 5)\n",
      "('Still Life with Bread Crumbs', 26.41, 3)\n",
      "('Atlas Shrugged', 26.58, 5)\n",
      "('The Infinities', 27.41, 1)\n",
      "('The Bette Davis Club', 30.66, 3)\n",
      "('The Little Paris Bookshop', 24.73, 3)\n",
      "('My Mrs. Brown', 24.48, 3)\n",
      "('Soumission', 50.1, 1)\n",
      "('The Murder That Never Was (Forensic Instincts #5)', 54.11, 3)\n",
      "('Inferno (Robert Langdon #4)', 41.0, 5)\n",
      "('Big Little Lies', 22.11, 1)\n",
      "('Crazy Rich Asians (Crazy Rich Asians #1)', 49.13, 5)\n",
      "('Jurassic Park (Jurassic Park #1)', 44.97, 1)\n",
      "('Kitchens of the Great Midwest', 57.2, 5)\n",
      "('Sister Dear', 40.2, 4)\n",
      "('Bright Lines', 39.07, 5)\n",
      "('Private Paris (Private #10)', 47.61, 5)\n",
      "('The Shack', 28.03, 1)\n",
      "('Tuesday Nights in 1980', 21.04, 2)\n",
      "('Me Before You (Me Before You #1)', 19.02, 1)\n",
      "('The Silent Wife', 12.34, 5)\n",
      "('The Expatriates', 44.58, 2)\n",
      "('Memoirs of a Geisha', 49.67, 3)\n",
      "('Daredevils', 16.34, 3)\n",
      "('Cometh the Hour (The Clifton Chronicles #6)', 25.01, 3)\n",
      "('The Bourne Identity (Jason Bourne #1)', 42.78, 4)\n",
      "('Finders Keepers (Bill Hodges Trilogy #2)', 53.53, 5)\n",
      "('Eight Hundred Grapes', 14.39, 4)\n",
      "(\"Miller's Valley\", 58.54, 2)\n",
      "('The Regional Office Is Under Attack!', 51.36, 5)\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# APARTADO 2 #\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "URL = 'https://books.toscrape.com/'\n",
    "def url_categoria(nombre):\n",
    "    \"\"\" Devuelve la URL de la página principal de una categoría a partir de su nombre (ignorar\n",
    "        espacios al principio y final y también diferencias en mayúsculas/minúsculas) \"\"\"\n",
    "    r = requests.get(URL)\n",
    "    # Corregimos el encoding\n",
    "    r.encoding = r.apparent_encoding\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #https://www.geeksforgeeks.org/beautifulsoup-search-by-text-inside-a-tag/\n",
    "    etiquetas = soup.find_all(lambda tag: tag.name==\"a\" and tag.text.strip().lower()==nombre.strip().lower())\n",
    "    \n",
    "    if(len(etiquetas)==0):\n",
    "        return None\n",
    "    else:\n",
    "        return URL+etiquetas[0].attrs[\"href\"]\n",
    "\n",
    "\n",
    "def number_from_text(texto):\n",
    "    \"\"\"\n",
    "    Devuelve el numero que representa el texto \n",
    "    que llega por parametro\n",
    "    \"\"\"\n",
    "    numeros={\n",
    "        'one':1,\n",
    "        'two':2,\n",
    "        'three':3,\n",
    "        'four':4,\n",
    "        'five':5\n",
    "    }\n",
    "    return numeros.get(texto.lower(),None)\n",
    "\n",
    "def libros_de_la_pagina(soup):\n",
    "    \"\"\"\n",
    "    Devuelve un conjunto con todos los libros que se ven \n",
    "    \"\"\"\n",
    "    etiquetas=soup.find_all(\"article\",{'class':\"product_pod\"})\n",
    "    libros=set()\n",
    "    for etiqueta in etiquetas:\n",
    "        #Siempre las estrellas son la primera P\n",
    "        p=etiqueta.find(\"p\")\n",
    "        # Esta p no es la misma que la primera\n",
    "        precio=etiqueta.find(\"p\",{'class':\"price_color\"}).text[1:]\n",
    "        titulo=etiqueta.find(\"h3\").find(\"a\").attrs[\"title\"]\n",
    "        libro_actual=(titulo,float(precio),number_from_text(p.attrs[\"class\"][1]))\n",
    "        libros.add(libro_actual)\n",
    "    return libros\n",
    "\n",
    "def todas_las_paginas(url):\n",
    "    \"\"\" Sigue la paginación recopilando todas las URL *absolutas* atravesadas\n",
    "     y los libros que se encuentran en esta \"\"\"\n",
    "    lista=[url]\n",
    "    r = requests.get(url)\n",
    "    r.encoding = r.apparent_encoding  # Corregimos el encoding\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    conjunto=libros_de_la_pagina(soup)\n",
    "    boton_siguiente=soup.find(\"li\",{'class':\"next\"})\n",
    "    if(boton_siguiente is None):\n",
    "        return lista, conjunto\n",
    "    else:\n",
    "        pagina_siguiente=boton_siguiente.find(\"a\").attrs[\"href\"]\n",
    "        siguiente_url=urljoin(url,pagina_siguiente)\n",
    "        return lista+todas_las_paginas(siguiente_url)[0],conjunto |todas_las_paginas(siguiente_url)[1]\n",
    "\n",
    "def libros_categoria(nombre):\n",
    "    \"\"\" Dado el nombre de una categoría, devuelve un conjunto de tuplas \n",
    "        (titulo, precio, valoracion), donde el precio será un número real y la \n",
    "        valoración un número natural \"\"\"\n",
    "    cat_url=url_categoria(nombre)\n",
    "    if cat_url is None:\n",
    "        return set()\n",
    "    else:\n",
    "       return todas_las_paginas(cat_url)[1]\n",
    "    \n",
    "aux=libros_categoria(\"fiction\")\n",
    "for l in aux:\n",
    "    print(l)\n",
    "print(len(aux))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
